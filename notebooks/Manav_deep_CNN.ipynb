{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import all relevant libraries\n",
    "import warnings\n",
    "def fxn(): \n",
    "\twarnings.warn(\"deprecated\",DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings( ):\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn( )\n",
    "\n",
    "# Keras imports\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, UpSampling1D, BatchNormalization, MaxPooling1D, MaxPooling2D, Permute, Flatten, Softmax, Dense, Dropout, Conv1D, Conv2D, Conv2DTranspose, AveragePooling1D, AveragePooling2D, Activation, Reshape\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Other\n",
    "import numpy as np\n",
    "import h5py\n",
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data from specific trial\n",
    "def get_trial(trial_num):    \n",
    "    trial = h5py.File('../data/A0' + str(trial_num) + 'T_slice.mat', 'r')\n",
    "    X = np.copy(trial['image'])\n",
    "    y = np.copy(trial['type'])\n",
    "    y = y[0,0:X.shape[0]:1]\n",
    "    y = np.asarray(y, dtype=np.int32)\n",
    "    y -= 769                            # shift class labels to [0-3]\n",
    "    X = np.nan_to_num(X)[:, :22, :]     # remove EOG channels\n",
    "    return X, y\n",
    "\n",
    "def get_all_trials():\n",
    "    X_total = np.concatenate([get_trial(trial_num)[0] for trial_num in range(1, 10)], axis=0)\n",
    "    y_total = np.concatenate([get_trial(trial_num)[1] for trial_num in range(1, 10)], axis=0)\n",
    "    return X_total, y_total\n",
    "\n",
    "def stratified_CV_split(X, y, k):\n",
    "    ''' Returns a stratified train/test split, for k number of splits. Split amount\n",
    "    is based on k (equal splits).\n",
    "    Return value is in the form [(train indices, test indices), ... for k folds ]\n",
    "    '''\n",
    "    skf = StratifiedKFold(n_splits=k)\n",
    "    return skf.split(X, y)\n",
    "\n",
    "def stratified_train_test_split(X, y, k, num_trials):\n",
    "    ''' Returns a stratified train/test split, for k number of splits. Test size is \n",
    "    50 * number of trials X is composed of.\n",
    "    Return value is in the form [(train indices, test indices), ... for k folds ]\n",
    "    '''\n",
    "    sss = StratifiedShuffleSplit(n_splits=k, test_size=50*num_trials)\n",
    "    return sss.split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the data from all the people and generate train/test split\n",
    "X, y = get_all_trials()\n",
    "y_cat = keras.utils.to_categorical(y, num_classes=4)\n",
    "#tt_splits = stratified_train_test_split(X, y, 5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y )\n",
    "\n",
    "one_hot_train = keras.utils.to_categorical(y_train)\n",
    "one_hot_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "\n",
    "# The data for each trial is of the shape (288, 22, 1000)\n",
    "#   There are 288 samples per trial (12 of each class per \"run\", 4 classes, 6 \"runs\" \n",
    "#                                   at different time periods of the day)\n",
    "#   There are 22 electrodes from the EEG (represents spatial aspect of the signals)\n",
    "#   There are 1000 time units (4 seconds of data, sampled at 250Hz). The first 250 units\n",
    "#                                   are when no movement occurs (but the cue is heard) and\n",
    "#                                   the next 750 units are when the movement occurs\n",
    "# The labels for each trial belong in one of 4 classes\n",
    "#   0 - left\n",
    "#   1 - right\n",
    "#   2 - foot\n",
    "#   3 - tongue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 330, 1, 25)\n",
      "(None, 107, 1, 50)\n",
      "(None, 32, 1, 100)\n",
      "(None, 7, 1, 200)\n",
      "(None, 4)\n",
      "(1944, 22, 1000)\n",
      "(1944, 1000, 22)\n",
      "(1944, 22, 1000)\n",
      "(1944, 1000, 22)\n",
      "Train on 1944 samples, validate on 648 samples\n",
      "Epoch 1/150\n",
      "1944/1944 [==============================] - 25s 13ms/step - loss: 2.3864 - acc: 0.2613 - val_loss: 1.4869 - val_acc: 0.2994\n",
      "Epoch 2/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 1.9567 - acc: 0.3097 - val_loss: 1.3802 - val_acc: 0.3519\n",
      "Epoch 3/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 1.7762 - acc: 0.3380 - val_loss: 1.3284 - val_acc: 0.3843\n",
      "Epoch 4/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 1.5997 - acc: 0.3657 - val_loss: 1.2727 - val_acc: 0.4090\n",
      "Epoch 5/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 1.5483 - acc: 0.3827 - val_loss: 1.2385 - val_acc: 0.4352\n",
      "Epoch 6/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 1.4829 - acc: 0.4120 - val_loss: 1.1957 - val_acc: 0.4537\n",
      "Epoch 7/150\n",
      "1944/1944 [==============================] - 28s 15ms/step - loss: 1.4129 - acc: 0.4156 - val_loss: 1.2413 - val_acc: 0.3935\n",
      "Epoch 8/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 1.3542 - acc: 0.4470 - val_loss: 1.2741 - val_acc: 0.3873\n",
      "Epoch 9/150\n",
      "1944/1944 [==============================] - 29s 15ms/step - loss: 1.3323 - acc: 0.4542 - val_loss: 1.2138 - val_acc: 0.4352\n",
      "Epoch 10/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 1.3179 - acc: 0.4594 - val_loss: 1.2809 - val_acc: 0.3951\n",
      "Epoch 11/150\n",
      "1944/1944 [==============================] - 26s 13ms/step - loss: 1.2742 - acc: 0.4815 - val_loss: 1.1785 - val_acc: 0.4815\n",
      "Epoch 12/150\n",
      "1944/1944 [==============================] - 25s 13ms/step - loss: 1.2698 - acc: 0.4933 - val_loss: 1.2938 - val_acc: 0.4213\n",
      "Epoch 13/150\n",
      "1944/1944 [==============================] - 24s 12ms/step - loss: 1.2322 - acc: 0.4954 - val_loss: 1.2260 - val_acc: 0.4691\n",
      "Epoch 14/150\n",
      "1944/1944 [==============================] - 24s 12ms/step - loss: 1.1775 - acc: 0.5180 - val_loss: 1.3080 - val_acc: 0.4105\n",
      "Epoch 15/150\n",
      "1944/1944 [==============================] - 25s 13ms/step - loss: 1.1657 - acc: 0.5237 - val_loss: 1.0837 - val_acc: 0.5216\n",
      "Epoch 16/150\n",
      "1944/1944 [==============================] - 25s 13ms/step - loss: 1.1853 - acc: 0.5432 - val_loss: 1.1562 - val_acc: 0.4769\n",
      "Epoch 17/150\n",
      "1944/1944 [==============================] - 25s 13ms/step - loss: 1.1361 - acc: 0.5437 - val_loss: 1.1029 - val_acc: 0.5324\n",
      "Epoch 18/150\n",
      "1944/1944 [==============================] - 25s 13ms/step - loss: 1.0566 - acc: 0.5736 - val_loss: 1.1089 - val_acc: 0.5463\n",
      "Epoch 19/150\n",
      "1944/1944 [==============================] - 25s 13ms/step - loss: 1.0714 - acc: 0.5736 - val_loss: 1.1445 - val_acc: 0.5077\n",
      "Epoch 20/150\n",
      "1944/1944 [==============================] - 26s 13ms/step - loss: 1.0576 - acc: 0.5710 - val_loss: 1.1027 - val_acc: 0.5370\n",
      "Epoch 21/150\n",
      "1944/1944 [==============================] - 26s 14ms/step - loss: 1.0402 - acc: 0.5761 - val_loss: 1.1576 - val_acc: 0.5015\n",
      "Epoch 22/150\n",
      "1944/1944 [==============================] - 25s 13ms/step - loss: 0.9955 - acc: 0.6024 - val_loss: 1.0862 - val_acc: 0.5340\n",
      "Epoch 23/150\n",
      "1944/1944 [==============================] - 25s 13ms/step - loss: 0.9741 - acc: 0.6147 - val_loss: 1.0833 - val_acc: 0.5448\n",
      "Epoch 24/150\n",
      "1944/1944 [==============================] - 25s 13ms/step - loss: 0.9667 - acc: 0.6137 - val_loss: 0.9640 - val_acc: 0.5880\n",
      "Epoch 25/150\n",
      "1944/1944 [==============================] - 25s 13ms/step - loss: 0.9350 - acc: 0.6312 - val_loss: 0.9562 - val_acc: 0.6003\n",
      "Epoch 26/150\n",
      "1944/1944 [==============================] - 25s 13ms/step - loss: 0.9251 - acc: 0.6415 - val_loss: 0.9381 - val_acc: 0.5972\n",
      "Epoch 27/150\n",
      "1944/1944 [==============================] - 25s 13ms/step - loss: 0.9159 - acc: 0.6389 - val_loss: 1.0080 - val_acc: 0.5741\n",
      "Epoch 28/150\n",
      "1944/1944 [==============================] - 25s 13ms/step - loss: 0.8961 - acc: 0.6430 - val_loss: 0.8797 - val_acc: 0.6373\n",
      "Epoch 29/150\n",
      "1944/1944 [==============================] - 26s 14ms/step - loss: 0.8941 - acc: 0.6317 - val_loss: 0.9973 - val_acc: 0.5972\n",
      "Epoch 30/150\n",
      "1944/1944 [==============================] - 24s 13ms/step - loss: 0.8911 - acc: 0.6435 - val_loss: 0.8682 - val_acc: 0.6373\n",
      "Epoch 31/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.8479 - acc: 0.6795 - val_loss: 0.9945 - val_acc: 0.5895\n",
      "Epoch 32/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 0.8252 - acc: 0.6775 - val_loss: 0.9338 - val_acc: 0.5972\n",
      "Epoch 33/150\n",
      "1944/1944 [==============================] - 28s 15ms/step - loss: 0.8220 - acc: 0.6780 - val_loss: 0.8458 - val_acc: 0.6481\n",
      "Epoch 34/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 0.7949 - acc: 0.6795 - val_loss: 0.9070 - val_acc: 0.6435\n",
      "Epoch 35/150\n",
      "1944/1944 [==============================] - 28s 15ms/step - loss: 0.7810 - acc: 0.7052 - val_loss: 0.8318 - val_acc: 0.6759\n",
      "Epoch 36/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 0.7583 - acc: 0.7001 - val_loss: 0.8220 - val_acc: 0.6713\n",
      "Epoch 37/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 0.7543 - acc: 0.7140 - val_loss: 0.8335 - val_acc: 0.6620\n",
      "Epoch 38/150\n",
      "1944/1944 [==============================] - 29s 15ms/step - loss: 0.7547 - acc: 0.7001 - val_loss: 0.8157 - val_acc: 0.6821\n",
      "Epoch 39/150\n",
      "1944/1944 [==============================] - 28s 15ms/step - loss: 0.7131 - acc: 0.7155 - val_loss: 0.8751 - val_acc: 0.6651\n",
      "Epoch 40/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 0.7101 - acc: 0.7248 - val_loss: 0.7954 - val_acc: 0.6667\n",
      "Epoch 41/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 0.7101 - acc: 0.7160 - val_loss: 0.8241 - val_acc: 0.6590\n",
      "Epoch 42/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.7134 - acc: 0.7258 - val_loss: 0.8712 - val_acc: 0.6466\n",
      "Epoch 43/150\n",
      "1944/1944 [==============================] - 30s 15ms/step - loss: 0.7193 - acc: 0.7181 - val_loss: 0.9064 - val_acc: 0.6528\n",
      "Epoch 44/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 0.6530 - acc: 0.7423 - val_loss: 0.8043 - val_acc: 0.6728\n",
      "Epoch 45/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.6744 - acc: 0.7346 - val_loss: 0.8274 - val_acc: 0.6744\n",
      "Epoch 46/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 0.6464 - acc: 0.7407 - val_loss: 0.7883 - val_acc: 0.6867\n",
      "Epoch 47/150\n",
      "1944/1944 [==============================] - 30s 15ms/step - loss: 0.6498 - acc: 0.7526 - val_loss: 0.8907 - val_acc: 0.6420\n",
      "Epoch 48/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 0.6926 - acc: 0.7371 - val_loss: 0.8067 - val_acc: 0.6620\n",
      "Epoch 49/150\n",
      "1944/1944 [==============================] - 30s 15ms/step - loss: 0.6467 - acc: 0.7335 - val_loss: 0.8143 - val_acc: 0.6821\n",
      "Epoch 50/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.6249 - acc: 0.7546 - val_loss: 0.8529 - val_acc: 0.6713\n",
      "Epoch 51/150\n",
      "1944/1944 [==============================] - 28s 15ms/step - loss: 0.6006 - acc: 0.7572 - val_loss: 0.8395 - val_acc: 0.6497\n",
      "Epoch 52/150\n",
      "1944/1944 [==============================] - 29s 15ms/step - loss: 0.6020 - acc: 0.7639 - val_loss: 0.7604 - val_acc: 0.6929\n",
      "Epoch 53/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 0.6055 - acc: 0.7541 - val_loss: 0.9356 - val_acc: 0.6451\n",
      "Epoch 54/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.6083 - acc: 0.7706 - val_loss: 0.7786 - val_acc: 0.6960\n",
      "Epoch 55/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.5779 - acc: 0.7803 - val_loss: 0.8016 - val_acc: 0.6806\n",
      "Epoch 56/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.5717 - acc: 0.7773 - val_loss: 0.7873 - val_acc: 0.6883\n",
      "Epoch 57/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 0.5434 - acc: 0.7906 - val_loss: 0.7371 - val_acc: 0.6991\n",
      "Epoch 58/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 0.5389 - acc: 0.8030 - val_loss: 0.7785 - val_acc: 0.6821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "1944/1944 [==============================] - 29s 15ms/step - loss: 0.5520 - acc: 0.7855 - val_loss: 0.9045 - val_acc: 0.6543\n",
      "Epoch 60/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 0.5308 - acc: 0.8035 - val_loss: 0.7600 - val_acc: 0.6821\n",
      "Epoch 61/150\n",
      "1944/1944 [==============================] - 26s 13ms/step - loss: 0.5351 - acc: 0.7989 - val_loss: 0.7477 - val_acc: 0.6960\n",
      "Epoch 62/150\n",
      "1944/1944 [==============================] - 26s 13ms/step - loss: 0.5449 - acc: 0.7819 - val_loss: 0.7563 - val_acc: 0.7006\n",
      "Epoch 63/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.5554 - acc: 0.7855 - val_loss: 0.8150 - val_acc: 0.6728\n",
      "Epoch 64/150\n",
      "1944/1944 [==============================] - 28s 15ms/step - loss: 0.4988 - acc: 0.7963 - val_loss: 0.7568 - val_acc: 0.7114\n",
      "Epoch 65/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 0.5341 - acc: 0.7968 - val_loss: 0.8499 - val_acc: 0.6914\n",
      "Epoch 66/150\n",
      "1944/1944 [==============================] - 29s 15ms/step - loss: 0.5098 - acc: 0.8056 - val_loss: 0.7673 - val_acc: 0.7130\n",
      "Epoch 67/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 0.5181 - acc: 0.8020 - val_loss: 0.7975 - val_acc: 0.7037\n",
      "Epoch 68/150\n",
      "1944/1944 [==============================] - 28s 15ms/step - loss: 0.5095 - acc: 0.7989 - val_loss: 0.8784 - val_acc: 0.6512\n",
      "Epoch 69/150\n",
      "1944/1944 [==============================] - 29s 15ms/step - loss: 0.4975 - acc: 0.8210 - val_loss: 0.8436 - val_acc: 0.6713\n",
      "Epoch 70/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 0.4753 - acc: 0.8128 - val_loss: 0.7985 - val_acc: 0.6991\n",
      "Epoch 71/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 0.4506 - acc: 0.8230 - val_loss: 0.8865 - val_acc: 0.6790\n",
      "Epoch 72/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 0.4349 - acc: 0.8323 - val_loss: 0.7951 - val_acc: 0.6775\n",
      "Epoch 73/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.4515 - acc: 0.8230 - val_loss: 0.8644 - val_acc: 0.6929\n",
      "Epoch 74/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.4441 - acc: 0.8318 - val_loss: 0.8424 - val_acc: 0.6759\n",
      "Epoch 75/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.4449 - acc: 0.8266 - val_loss: 0.7909 - val_acc: 0.6944\n",
      "Epoch 76/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.4187 - acc: 0.8395 - val_loss: 0.8050 - val_acc: 0.6975\n",
      "Epoch 77/150\n",
      "1944/1944 [==============================] - 30s 16ms/step - loss: 0.4134 - acc: 0.8436 - val_loss: 0.9227 - val_acc: 0.6636\n",
      "Epoch 78/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 0.4428 - acc: 0.8344 - val_loss: 0.9092 - val_acc: 0.6590\n",
      "Epoch 79/150\n",
      "1944/1944 [==============================] - 30s 15ms/step - loss: 0.4168 - acc: 0.8390 - val_loss: 0.8941 - val_acc: 0.6713\n",
      "Epoch 80/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.4419 - acc: 0.8354 - val_loss: 0.8756 - val_acc: 0.6759\n",
      "Epoch 81/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.4352 - acc: 0.8416 - val_loss: 0.8668 - val_acc: 0.6759\n",
      "Epoch 82/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 0.4068 - acc: 0.8359 - val_loss: 0.8923 - val_acc: 0.6698\n",
      "Epoch 83/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.4106 - acc: 0.8297 - val_loss: 0.8453 - val_acc: 0.6929\n",
      "Epoch 84/150\n",
      "1944/1944 [==============================] - 29s 15ms/step - loss: 0.4219 - acc: 0.8333 - val_loss: 0.8621 - val_acc: 0.6636\n",
      "Epoch 85/150\n",
      "1944/1944 [==============================] - 29s 15ms/step - loss: 0.4026 - acc: 0.8534 - val_loss: 0.8141 - val_acc: 0.6867\n",
      "Epoch 86/150\n",
      "1944/1944 [==============================] - 31s 16ms/step - loss: 0.3721 - acc: 0.8539 - val_loss: 0.8053 - val_acc: 0.6991\n",
      "Epoch 87/150\n",
      "1944/1944 [==============================] - 29s 15ms/step - loss: 0.3800 - acc: 0.8601 - val_loss: 0.9035 - val_acc: 0.6806\n",
      "Epoch 88/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.3510 - acc: 0.8642 - val_loss: 0.8528 - val_acc: 0.6914\n",
      "Epoch 89/150\n",
      "1944/1944 [==============================] - 26s 14ms/step - loss: 0.4098 - acc: 0.8498 - val_loss: 0.8278 - val_acc: 0.7083\n",
      "Epoch 90/150\n",
      "1944/1944 [==============================] - 30s 16ms/step - loss: 0.3518 - acc: 0.8709 - val_loss: 0.9277 - val_acc: 0.6852\n",
      "Epoch 91/150\n",
      "1944/1944 [==============================] - 30s 15ms/step - loss: 0.3395 - acc: 0.8786 - val_loss: 0.8328 - val_acc: 0.6991\n",
      "Epoch 92/150\n",
      "1944/1944 [==============================] - 30s 16ms/step - loss: 0.3972 - acc: 0.8560 - val_loss: 0.9229 - val_acc: 0.6790\n",
      "Epoch 93/150\n",
      "1944/1944 [==============================] - 29s 15ms/step - loss: 0.3789 - acc: 0.8596 - val_loss: 0.9519 - val_acc: 0.6790\n",
      "Epoch 94/150\n",
      "1944/1944 [==============================] - 30s 15ms/step - loss: 0.3886 - acc: 0.8503 - val_loss: 0.8630 - val_acc: 0.6867\n",
      "Epoch 95/150\n",
      "1944/1944 [==============================] - 30s 16ms/step - loss: 0.3419 - acc: 0.8709 - val_loss: 0.9745 - val_acc: 0.6651\n",
      "Epoch 96/150\n",
      "1944/1944 [==============================] - 29s 15ms/step - loss: 0.3663 - acc: 0.8565 - val_loss: 0.8461 - val_acc: 0.6960\n",
      "Epoch 97/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.3189 - acc: 0.8868 - val_loss: 0.8645 - val_acc: 0.6883\n",
      "Epoch 98/150\n",
      "1944/1944 [==============================] - 30s 15ms/step - loss: 0.3343 - acc: 0.8796 - val_loss: 0.8685 - val_acc: 0.6790\n",
      "Epoch 99/150\n",
      "1944/1944 [==============================] - 30s 15ms/step - loss: 0.3366 - acc: 0.8663 - val_loss: 0.9084 - val_acc: 0.6790\n",
      "Epoch 100/150\n",
      "1944/1944 [==============================] - 31s 16ms/step - loss: 0.3422 - acc: 0.8668 - val_loss: 0.9077 - val_acc: 0.6713\n",
      "Epoch 101/150\n",
      "1944/1944 [==============================] - 34s 17ms/step - loss: 0.3084 - acc: 0.8796 - val_loss: 0.8917 - val_acc: 0.6790\n",
      "Epoch 102/150\n",
      "1944/1944 [==============================] - 29s 15ms/step - loss: 0.3412 - acc: 0.8781 - val_loss: 0.8793 - val_acc: 0.6975\n",
      "Epoch 103/150\n",
      "1944/1944 [==============================] - 29s 15ms/step - loss: 0.3056 - acc: 0.8791 - val_loss: 0.9459 - val_acc: 0.6806\n",
      "Epoch 104/150\n",
      "1944/1944 [==============================] - 29s 15ms/step - loss: 0.3347 - acc: 0.8657 - val_loss: 0.8773 - val_acc: 0.6914\n",
      "Epoch 105/150\n",
      "1944/1944 [==============================] - 29s 15ms/step - loss: 0.3321 - acc: 0.8837 - val_loss: 0.8264 - val_acc: 0.7052\n",
      "Epoch 106/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.3254 - acc: 0.8776 - val_loss: 0.9187 - val_acc: 0.6744\n",
      "Epoch 107/150\n",
      "1944/1944 [==============================] - 26s 13ms/step - loss: 0.3217 - acc: 0.8832 - val_loss: 0.9439 - val_acc: 0.6836\n",
      "Epoch 108/150\n",
      "1944/1944 [==============================] - 29s 15ms/step - loss: 0.3302 - acc: 0.8750 - val_loss: 0.9719 - val_acc: 0.6759\n",
      "Epoch 109/150\n",
      "1944/1944 [==============================] - 29s 15ms/step - loss: 0.3267 - acc: 0.8781 - val_loss: 0.9497 - val_acc: 0.6836\n",
      "Epoch 110/150\n",
      "1944/1944 [==============================] - 28s 15ms/step - loss: 0.2985 - acc: 0.8843 - val_loss: 0.9620 - val_acc: 0.6759\n",
      "Epoch 111/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.3324 - acc: 0.8781 - val_loss: 0.9891 - val_acc: 0.6713\n",
      "Epoch 112/150\n",
      "1944/1944 [==============================] - 30s 15ms/step - loss: 0.3231 - acc: 0.8786 - val_loss: 0.8923 - val_acc: 0.6867\n",
      "Epoch 113/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.2813 - acc: 0.8925 - val_loss: 0.8722 - val_acc: 0.6852\n",
      "Epoch 114/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.3584 - acc: 0.8632 - val_loss: 0.8811 - val_acc: 0.6836\n",
      "Epoch 115/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 0.3187 - acc: 0.8812 - val_loss: 0.9003 - val_acc: 0.6929\n",
      "Epoch 116/150\n",
      "1944/1944 [==============================] - 28s 15ms/step - loss: 0.3272 - acc: 0.8812 - val_loss: 0.8830 - val_acc: 0.6775\n",
      "Epoch 117/150\n",
      "1944/1944 [==============================] - 26s 14ms/step - loss: 0.3108 - acc: 0.8837 - val_loss: 0.8963 - val_acc: 0.6914\n",
      "Epoch 118/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 31s 16ms/step - loss: 0.3029 - acc: 0.8915 - val_loss: 0.8799 - val_acc: 0.6852\n",
      "Epoch 119/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.3012 - acc: 0.8904 - val_loss: 0.8976 - val_acc: 0.6806\n",
      "Epoch 120/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.2805 - acc: 0.8956 - val_loss: 0.9281 - val_acc: 0.6806\n",
      "Epoch 121/150\n",
      "1944/1944 [==============================] - 26s 14ms/step - loss: 0.2636 - acc: 0.8945 - val_loss: 0.9514 - val_acc: 0.6759\n",
      "Epoch 122/150\n",
      "1944/1944 [==============================] - 26s 14ms/step - loss: 0.2757 - acc: 0.8935 - val_loss: 0.8896 - val_acc: 0.6744\n",
      "Epoch 123/150\n",
      "1944/1944 [==============================] - 26s 13ms/step - loss: 0.2566 - acc: 0.9043 - val_loss: 0.9789 - val_acc: 0.6821\n",
      "Epoch 124/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.2717 - acc: 0.9012 - val_loss: 0.9289 - val_acc: 0.6836\n",
      "Epoch 125/150\n",
      "1944/1944 [==============================] - 32s 17ms/step - loss: 0.2836 - acc: 0.8889 - val_loss: 0.9778 - val_acc: 0.7022\n",
      "Epoch 126/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.2711 - acc: 0.8981 - val_loss: 0.9680 - val_acc: 0.6806\n",
      "Epoch 127/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 0.2786 - acc: 0.8879 - val_loss: 1.0142 - val_acc: 0.6759\n",
      "Epoch 128/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.2811 - acc: 0.8945 - val_loss: 0.9287 - val_acc: 0.6806\n",
      "Epoch 129/150\n",
      "1944/1944 [==============================] - 25s 13ms/step - loss: 0.2629 - acc: 0.9028 - val_loss: 0.9539 - val_acc: 0.6759\n",
      "Epoch 130/150\n",
      "1944/1944 [==============================] - 25s 13ms/step - loss: 0.2370 - acc: 0.9151 - val_loss: 0.9455 - val_acc: 0.6852\n",
      "Epoch 131/150\n",
      "1944/1944 [==============================] - 33s 17ms/step - loss: 0.2728 - acc: 0.8956 - val_loss: 0.9482 - val_acc: 0.6898\n",
      "Epoch 132/150\n",
      "1944/1944 [==============================] - 28s 15ms/step - loss: 0.2846 - acc: 0.9017 - val_loss: 0.9518 - val_acc: 0.6836\n",
      "Epoch 133/150\n",
      "1944/1944 [==============================] - 28s 15ms/step - loss: 0.2766 - acc: 0.9048 - val_loss: 0.9534 - val_acc: 0.6975\n",
      "Epoch 134/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.2942 - acc: 0.8858 - val_loss: 0.9131 - val_acc: 0.7068\n",
      "Epoch 135/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 0.2628 - acc: 0.9064 - val_loss: 0.9162 - val_acc: 0.7006\n",
      "Epoch 136/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 0.2419 - acc: 0.9090 - val_loss: 0.9947 - val_acc: 0.6852\n",
      "Epoch 137/150\n",
      "1944/1944 [==============================] - 30s 15ms/step - loss: 0.2801 - acc: 0.8976 - val_loss: 0.9491 - val_acc: 0.6867\n",
      "Epoch 138/150\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 0.2687 - acc: 0.9007 - val_loss: 0.9731 - val_acc: 0.6991\n",
      "Epoch 139/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.2559 - acc: 0.9084 - val_loss: 0.8896 - val_acc: 0.7022\n",
      "Epoch 140/150\n",
      "1944/1944 [==============================] - 29s 15ms/step - loss: 0.2798 - acc: 0.8961 - val_loss: 0.9606 - val_acc: 0.6991\n",
      "Epoch 141/150\n",
      "1944/1944 [==============================] - 28s 15ms/step - loss: 0.2679 - acc: 0.8997 - val_loss: 0.9936 - val_acc: 0.6836\n",
      "Epoch 142/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.2763 - acc: 0.9007 - val_loss: 1.0102 - val_acc: 0.6790\n",
      "Epoch 143/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.2136 - acc: 0.9146 - val_loss: 1.0293 - val_acc: 0.6636\n",
      "Epoch 144/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.2661 - acc: 0.9033 - val_loss: 0.9442 - val_acc: 0.6914\n",
      "Epoch 145/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.2262 - acc: 0.9198 - val_loss: 1.0329 - val_acc: 0.6759\n",
      "Epoch 146/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.2492 - acc: 0.9064 - val_loss: 0.9476 - val_acc: 0.6883\n",
      "Epoch 147/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.2407 - acc: 0.9090 - val_loss: 0.9325 - val_acc: 0.6975\n",
      "Epoch 148/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.3105 - acc: 0.8894 - val_loss: 1.0202 - val_acc: 0.6898\n",
      "Epoch 149/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.2322 - acc: 0.9059 - val_loss: 1.0187 - val_acc: 0.6806\n",
      "Epoch 150/150\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 0.2527 - acc: 0.9069 - val_loss: 0.9700 - val_acc: 0.6867\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_26_input to have 4 dimensions, but got array with shape (648, 1000, 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-46c826341540>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mone_hot_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1002\u001b[0m                                    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m                                    \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                    steps=steps)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1776\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `_test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1481\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1483\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1484\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1485\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_26_input to have 4 dimensions, but got array with shape (648, 1000, 22)"
     ]
    }
   ],
   "source": [
    "# Deep Implementation CNN\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Conv Pool Block 1\n",
    "model.add(Conv2D(filters=25, kernel_size=(10,1), input_shape=(1000, 22, 1), kernel_initializer = 'glorot_normal', strides=1, data_format=\"channels_last\"))\n",
    "model.add(Conv2D(filters=25, kernel_size=(1,22), kernel_initializer = 'glorot_normal' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation = 'elu'))\n",
    "model.add(MaxPooling2D(pool_size = (3,1), strides = (3,1)))\n",
    "model.add(Dropout(0.5))\n",
    "print(model.output_shape)\n",
    "\n",
    "\n",
    "\n",
    "# Conv Pool Block 2\n",
    "model.add(Conv2D(filters = 50, kernel_size = (10,1), activation = 'elu', kernel_initializer = 'glorot_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation = 'elu'))\n",
    "model.add(MaxPooling2D(pool_size = (3,1), strides = (3,1)))\n",
    "model.add(Dropout(0.5))\n",
    "print(model.output_shape)\n",
    "\n",
    "# Conv Pool Block 3\n",
    "model.add(Conv2D(filters = 100, kernel_size = (10,1), activation = 'elu', kernel_initializer = 'glorot_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation = 'elu'))\n",
    "model.add(MaxPooling2D(pool_size = (3,1), strides = (3,1)))\n",
    "model.add(Dropout(0.5))\n",
    "print(model.output_shape)\n",
    "\n",
    "# Conv Pool Block 4\n",
    "model.add(Conv2D(filters = 200, kernel_size = (10,1), activation = 'elu', kernel_initializer = 'glorot_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation = 'elu'))\n",
    "model.add(MaxPooling2D(pool_size = (3,1), strides = (3,1)))\n",
    "model.add(Dropout(0.5))\n",
    "print(model.output_shape)\n",
    "\n",
    "# Dense Layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4, kernel_initializer='glorot_normal', activation = 'softmax'))\n",
    "print(model.output_shape)\n",
    "\n",
    "\n",
    "#Adam = Adam(lr=0.15)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "x_train = X_train.transpose((0,2,1))\n",
    "print(x_train.shape)\n",
    "\n",
    "x_test = X_test.transpose((0,2,1))\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(x_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "model.fit(x_train[:, :, :, None] , one_hot_train, epochs=150, batch_size=32, validation_data = (x_test[:, :, :, None], one_hot_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test[:, :, :, None], one_hot_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96995184818903601, 0.68672839506172845]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
