{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import all relevant libraries\n",
    "import warnings\n",
    "def fxn(): \n",
    "\twarnings.warn(\"deprecated\",DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings( ):\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn( )\n",
    "\n",
    "# Keras imports\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import SimpleRNN, LSTM, Input, UpSampling1D, BatchNormalization, MaxPooling1D, MaxPooling2D, Permute, Flatten, Softmax, Dense, Dropout, Conv1D, Conv2D, Conv2DTranspose, AveragePooling1D, AveragePooling2D, Activation, Reshape\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Other\n",
    "import numpy as np\n",
    "import h5py\n",
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data from specific trial\n",
    "def get_trial(trial_num):    \n",
    "    trial = h5py.File('../data/A0' + str(trial_num) + 'T_slice.mat', 'r')\n",
    "    X = np.copy(trial['image'])\n",
    "    y = np.copy(trial['type'])\n",
    "    y = y[0,0:X.shape[0]:1]\n",
    "    y = np.asarray(y, dtype=np.int32)\n",
    "    y -= 769                            # shift class labels to [0-3]\n",
    "    X = np.nan_to_num(X)[:, :22, :]     # remove EOG channels\n",
    "    return X, y\n",
    "\n",
    "def get_all_trials():\n",
    "    X_total = np.concatenate([get_trial(trial_num)[0] for trial_num in range(1, 9)], axis=0)\n",
    "    y_total = np.concatenate([get_trial(trial_num)[1] for trial_num in range(1, 9)], axis=0)\n",
    "    return X_total, y_total\n",
    "\n",
    "def stratified_train_test_split(X, y, k, num_trials):\n",
    "    ''' Returns a stratified train/test split, for k number of splits.\n",
    "    Return value is in the form [(train indices, test indices), ... for k folds ]\n",
    "    '''\n",
    "    sss = StratifiedShuffleSplit(n_splits=k, test_size=50*num_trials)\n",
    "    return sss.split(X, y)\n",
    "\n",
    "def generate_crops(X, y):\n",
    "    '''Crop the 4s trial into 2s crops at 0.1s intervals\n",
    "    (1000 timesteps > 500 timesteps, in 25 timestep intervals)\n",
    "    '''\n",
    "    new_X = []\n",
    "    new_y = []\n",
    "    for k in range(X.shape[0]):\n",
    "        for i in range(20):\n",
    "            new_X.append(X[(25*i):(25*i + 500)])\n",
    "            new_y.append(y[i])\n",
    "    return np.array(new_X), np.array(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "\n",
    "# Get the data from one person\n",
    "# X, y = get_trial(2)\n",
    "# num_trials = 1\n",
    "\n",
    "# Get the data from all the people\n",
    "X, y = get_all_trials()\n",
    "num_trials = 9\n",
    "\n",
    "\n",
    "# Generate crops\n",
    "X, y = generate_crops(X, y)\n",
    "\n",
    "# 0 mean and unit variance\n",
    "temp = np.reshape(X, (X.shape[0], -1))\n",
    "X = np.reshape(preprocessing.scale(temp), X.shape)\n",
    "\n",
    "# Generate train/test split\n",
    "y_cat = keras.utils.to_categorical(y, num_classes=4)\n",
    "tt_splits = stratified_train_test_split(X, y, num_folds, num_trials)\n",
    "\n",
    "print(tt_splits)\n",
    "\n",
    "# The data for each trial is of the shape (288, 22, 1000)\n",
    "#   There are 288 samples per trial (12 of each class per \"run\", 4 classes, 6 \"runs\" \n",
    "#                                   at different time periods of the day)\n",
    "#   There are 22 electrodes from the EEG (represents spatial aspect of the signals)\n",
    "#   There are 1000 time units (4 seconds of data, sampled at 250Hz). The first 250 units\n",
    "#                                   are when no movement occurs (but the cue is heard) and\n",
    "#                                   the next 750 units are when the movement occurs\n",
    "# The labels for each trial belong in one of 4 classes\n",
    "#   0 - left\n",
    "#   1 - right\n",
    "#   2 - foot\n",
    "#   3 - tongue\n",
    "\n",
    "# Set training params for NN\n",
    "batch_size = 32\n",
    "val_split = 0.2\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basic LSTM \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(32, input_shape = (1000,22)  ))\n",
    "\n",
    "model.add(Dense(units = 4, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "x_train = X_train.transpose((0,2,1))\n",
    "x_test = X_test.transpose((0,2,1))\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "model.fit(x_train[:, :, :] , one_hot_train, epochs=150, batch_size=32, validation_data = (x_test[:, :, :], one_hot_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LSTM with Conv 1D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "# 1D Convolutional Layer\n",
    "model.add(Conv1D(filters=25, kernel_size=10, input_shape=(1000, 22), kernel_initializer = 'glorot_normal', strides=1))\n",
    "\n",
    "\n",
    "# 3 LSTM Layers \n",
    "model.add(LSTM(32, return_sequences = True))\n",
    "model.add(LSTM(32, activation = 'relu', return_sequences = True))\n",
    "model.add(LSTM(32))\n",
    "\n",
    "# Dense Layer\n",
    "model.add(Dense(units = 4, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "x_train = X_train.transpose((0,2,1))\n",
    "x_test = X_test.transpose((0,2,1))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "model.fit(x_train[:, :, :] , one_hot_train, epochs=15, batch_size=32, validation_data = (x_test[:, :, :], one_hot_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple RNN\n",
    "\n",
    "num_epochs = 60\n",
    "\n",
    "\n",
    "def make_RNN():\n",
    "    # input is of the form: (sample, spatial, temporal)\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Permute((2, 1), input_shape=(22, 1000)))\n",
    "    model.add(Reshape((1000, 22, 1)))\n",
    "    \n",
    "    model.add(Conv2D(filters=25, kernel_size=(10,1), kernel_initializer = 'glorot_normal', strides=1, data_format=\"channels_last\"))\n",
    "    #print(model.output_shape)\n",
    "    model.add(Conv2D(filters=25, kernel_size=(1,22), kernel_initializer = 'glorot_normal' ))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation = 'elu'))\n",
    "    model.add(MaxPooling2D(pool_size = (3,1), strides = (3,1)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Conv Pool Block 2\n",
    "    model.add(Conv2D(filters = 50, kernel_size = (10,1), activation = 'elu', kernel_initializer = 'glorot_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation = 'elu'))\n",
    "    model.add(MaxPooling2D(pool_size = (3,1), strides = (3,1)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Permute((1, 3, 2)))\n",
    "    model.add(Reshape((107, 50)))\n",
    "    \n",
    "    # RNN layers\n",
    "    model.add(SimpleRNN(32, return_sequences=True))\n",
    "    model.add(SimpleRNN(32, return_sequences=True))\n",
    "    model.add(SimpleRNN(32, return_sequences=True))\n",
    "    model.add(SimpleRNN(32, return_sequences=True))\n",
    "    \n",
    "    # Dense layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=4, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='SGD',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "# make_GRU()\n",
    "  \n",
    "avg_acc = 0\n",
    "for train_idx, test_idx in tt_splits:\n",
    "    X_train = X[train_idx]\n",
    "    y_train = y_cat[train_idx]\n",
    "    X_test = X[test_idx]\n",
    "    y_test = y_cat[test_idx]\n",
    "    \n",
    "    model = make_RNN()\n",
    "    \n",
    "    history = model.fit(X_train, y_train, validation_split=val_split, epochs=num_epochs, batch_size=batch_size)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    metrics = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "    avg_acc += metrics[1]\n",
    "    print(metrics)\n",
    "    break\n",
    "\n",
    "print(avg_acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
