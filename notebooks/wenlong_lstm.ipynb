{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all relevant libraries\n",
    "import warnings\n",
    "def fxn(): \n",
    "\twarnings.warn(\"deprecated\",DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings( ):\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn( )\n",
    "\n",
    "# Keras imports\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Permute, Flatten, Softmax, Dense, Conv1D, Conv2D, Conv2DTranspose, AveragePooling2D, Activation, Reshape, Dropout, LSTM, GRU\n",
    "\n",
    "# Other\n",
    "import numpy as np\n",
    "import h5py\n",
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, StratifiedShuffleSplit\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# random seed for reproducability\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from specific trial\n",
    "def get_trial(trial_num):    \n",
    "    trial = h5py.File('../data/A0' + str(trial_num) + 'T_slice.mat', 'r')\n",
    "    X = np.copy(trial['image'])\n",
    "    y = np.copy(trial['type'])\n",
    "    y = y[0,0:X.shape[0]:1]\n",
    "    y = np.asarray(y, dtype=np.int32)\n",
    "    y -= 769                            # shift class labels to [0-3]\n",
    "    X = np.nan_to_num(X)[:, :22, :]     # remove EOG channels\n",
    "    return X, y\n",
    "\n",
    "def get_all_trials():\n",
    "    X_total = np.concatenate([get_trial(trial_num)[0] for trial_num in range(1, 9)], axis=0)\n",
    "    y_total = np.concatenate([get_trial(trial_num)[1] for trial_num in range(1, 9)], axis=0)\n",
    "    return X_total, y_total\n",
    "\n",
    "def stratified_train_test_split(X, y, k, num_trials):\n",
    "    ''' Returns a stratified train/test split, for k number of splits.\n",
    "    Return value is in the form [(train indices, test indices), ... for k folds ]\n",
    "    '''\n",
    "    sss = StratifiedShuffleSplit(n_splits=k, test_size=50*num_trials)\n",
    "    return sss.split(X, y)\n",
    "\n",
    "def generate_crops(X, y):\n",
    "    '''Crop the 4s trial into 2s crops at 0.1s intervals\n",
    "    (1000 timesteps > 500 timesteps, in 25 timestep intervals)\n",
    "    '''\n",
    "    new_X = []\n",
    "    new_y = []\n",
    "    for k in range(X.shape[0]):\n",
    "        for i in range(20):\n",
    "            new_X.append(X[(25*i):(25*i + 500)])\n",
    "            new_y.append(y[i])\n",
    "    return np.array(new_X), np.array(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "\n",
    "# Get the data from one person\n",
    "# X, y = get_trial(2)\n",
    "# num_trials = 1\n",
    "\n",
    "# Get the data from all the people\n",
    "X, y = get_all_trials()\n",
    "num_trials = 9\n",
    "\n",
    "\n",
    "# Generate crops\n",
    "X, y = generate_crops(X, y)\n",
    "\n",
    "# 0 mean and unit variance\n",
    "temp = np.reshape(X, (X.shape[0], -1))\n",
    "X = np.reshape(preprocessing.scale(temp), X.shape)\n",
    "\n",
    "# Generate train/test split\n",
    "y_cat = keras.utils.to_categorical(y, num_classes=4)\n",
    "tt_splits = stratified_train_test_split(X, y, num_folds, num_trials)\n",
    "\n",
    "print(tt_splits)\n",
    "\n",
    "# The data for each trial is of the shape (288, 22, 1000)\n",
    "#   There are 288 samples per trial (12 of each class per \"run\", 4 classes, 6 \"runs\" \n",
    "#                                   at different time periods of the day)\n",
    "#   There are 22 electrodes from the EEG (represents spatial aspect of the signals)\n",
    "#   There are 1000 time units (4 seconds of data, sampled at 250Hz). The first 250 units\n",
    "#                                   are when no movement occurs (but the cue is heard) and\n",
    "#                                   the next 750 units are when the movement occurs\n",
    "# The labels for each trial belong in one of 4 classes\n",
    "#   0 - left\n",
    "#   1 - right\n",
    "#   2 - foot\n",
    "#   3 - tongue\n",
    "\n",
    "# Set training params for NN\n",
    "batch_size = 32\n",
    "val_split = 0.2\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "permute_9 (Permute)          (None, 1000, 22)          0         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 1000, 128)         77312     \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 200)               25600200  \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 4)                 804       \n",
      "=================================================================\n",
      "Total params: 25,678,316\n",
      "Trainable params: 25,678,316\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1483 samples, validate on 371 samples\n",
      "Epoch 1/5\n",
      "1483/1483 [==============================] - 74s 50ms/step - loss: 1.3634 - acc: 0.3338 - val_loss: 1.3013 - val_acc: 0.3908\n",
      "Epoch 2/5\n",
      "1483/1483 [==============================] - 70s 47ms/step - loss: 1.0453 - acc: 0.5813 - val_loss: 1.2785 - val_acc: 0.4232\n",
      "Epoch 3/5\n",
      "1483/1483 [==============================] - 70s 47ms/step - loss: 0.8538 - acc: 0.6858 - val_loss: 1.2747 - val_acc: 0.4178\n",
      "Epoch 4/5\n",
      "1483/1483 [==============================] - 79s 54ms/step - loss: 0.6863 - acc: 0.7755 - val_loss: 1.2768 - val_acc: 0.4232\n",
      "Epoch 5/5\n",
      "1483/1483 [==============================] - 90s 61ms/step - loss: 0.5738 - acc: 0.8314 - val_loss: 1.2705 - val_acc: 0.4420\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1225ba1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 4s 10ms/step\n",
      "[1.3122327020433213, 0.4222222222222222]\n",
      "0.08444444444444445\n"
     ]
    }
   ],
   "source": [
    "# Create LSTM model\n",
    "\n",
    "# Simple LSTM model with 1 LSTM layer and some dense layers\n",
    "# LSTM layer accepts data in the form (samples, timesteps, features)\n",
    "\n",
    "def make_LSTM():\n",
    "    # input is of the form: (sample, spatial, temporal)\n",
    "    model = Sequential()\n",
    "    model.add(Permute((2, 1), input_shape=(22, 1000)))\n",
    "    \n",
    "    # LSTM layers\n",
    "    model.add(LSTM(128, dropout=0.0, recurrent_dropout=0.0, return_sequences=True))\n",
    "    \n",
    "    # Dense layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=200, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=4, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='SGD',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "avg_acc = 0\n",
    "for train_idx, test_idx in tt_splits:\n",
    "    X_train = X[train_idx]\n",
    "    y_train = y_cat[train_idx]\n",
    "    X_test = X[test_idx]\n",
    "    y_test = y_cat[test_idx]\n",
    "    \n",
    "    model = make_LSTM()\n",
    "    \n",
    "    history = model.fit(X_train, y_train, validation_split=val_split, epochs=num_epochs, batch_size=batch_size)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    metrics = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "    avg_acc += metrics[1]\n",
    "    print(metrics)\n",
    "    break\n",
    "\n",
    "avg_acc /= num_folds\n",
    "print(avg_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This previous example overfit pretty badly, so we'll try removing the dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "test_size=450 should be smaller than the number of samples 20",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-ce8d83530aa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mavg_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtt_splits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ece239_project/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1202\u001b[0m         \"\"\"\n\u001b[1;32m   1203\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ece239_project/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1532\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m         n_train, n_test = _validate_shuffle_split(n_samples, self.test_size,\n\u001b[0;32m-> 1534\u001b[0;31m                                                   self.train_size)\n\u001b[0m\u001b[1;32m   1535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ece239_project/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size)\u001b[0m\n\u001b[1;32m   1678\u001b[0m             test_size >= n_samples):\n\u001b[1;32m   1679\u001b[0m         raise ValueError('test_size=%d should be smaller than the number of '\n\u001b[0;32m-> 1680\u001b[0;31m                          'samples %d' % (test_size, n_samples))\n\u001b[0m\u001b[1;32m   1681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     if (train_size is not None and\n",
      "\u001b[0;31mValueError\u001b[0m: test_size=450 should be smaller than the number of samples 20"
     ]
    }
   ],
   "source": [
    "# Create LSTM model\n",
    "\n",
    "# Simple LSTM model with 1 LSTM layer and no dense layers\n",
    "# LSTM layer accepts data in the form (samples, timesteps, features)\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "def make_LSTM():\n",
    "    # input is of the form: (sample, spatial, temporal)\n",
    "    model = Sequential()\n",
    "    model.add(Permute((2, 1), input_shape=(22, 1000)))\n",
    "    \n",
    "    # LSTM layers\n",
    "    model.add(LSTM(32, dropout=0.0, recurrent_dropout=0.0, return_sequences=True))\n",
    "    \n",
    "    # Dense layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=4, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='SGD',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "avg_acc = 0\n",
    "for train_idx, test_idx in tt_splits:\n",
    "    X_train = X[train_idx]\n",
    "    y_train = y_cat[train_idx]\n",
    "    X_test = X[test_idx]\n",
    "    y_test = y_cat[test_idx]\n",
    "    \n",
    "    model = make_LSTM()\n",
    "    \n",
    "    history = model.fit(X_train, y_train, validation_split=val_split, epochs=num_epochs, batch_size=batch_size)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    metrics = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "    avg_acc += metrics[1]\n",
    "    print(metrics)\n",
    "    break\n",
    "\n",
    "avg_acc /= num_folds\n",
    "print(avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM model\n",
    "\n",
    "# Simple LSTM model with stacked LSTM layers (inspiration from NLP) - 3 layers\n",
    "# LSTM layer accepts data in the form (samples, timesteps, features)\n",
    "\n",
    "def make_LSTM():\n",
    "    # input is of the form: (sample, spatial, temporal)\n",
    "    model = Sequential()\n",
    "    model.add(Permute((2, 1), input_shape=(22, 1000)))\n",
    "    \n",
    "    # LSTM layers\n",
    "    model.add(LSTM(64, dropout=0.0, recurrent_dropout=0.0, return_sequences=True))\n",
    "    model.add(LSTM(64, dropout=0.0, recurrent_dropout=0.0, return_sequences=True))\n",
    "    model.add(LSTM(64, dropout=0.0, recurrent_dropout=0.0, return_sequences=True))\n",
    "    \n",
    "    # Dense layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=4, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='SGD',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "avg_acc = 0\n",
    "for train_idx, test_idx in tt_splits:\n",
    "    X_train = X[train_idx]\n",
    "    y_train = y_cat[train_idx]\n",
    "    X_test = X[test_idx]\n",
    "    y_test = y_cat[test_idx]\n",
    "    \n",
    "    model = make_LSTM()\n",
    "    \n",
    "    history = model.fit(X_train, y_train, validation_split=val_split, epochs=num_epochs, batch_size=batch_size)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    metrics = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "    avg_acc += metrics[1]\n",
    "    print(metrics)\n",
    "    break\n",
    "\n",
    "avg_acc /= num_folds\n",
    "print(avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM model\n",
    "\n",
    "# Simple LSTM model with stacked LSTM layers (inspiration from NLP) - 3 layers, with dropout\n",
    "# LSTM layer accepts data in the form (samples, timesteps, features)\n",
    "\n",
    "def make_LSTM():\n",
    "    # input is of the form: (sample, spatial, temporal)\n",
    "    model = Sequential()\n",
    "    model.add(Permute((2, 1), input_shape=(22, 1000)))\n",
    "    \n",
    "    # LSTM layers\n",
    "    model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.0, return_sequences=True))\n",
    "    model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.0, return_sequences=True))\n",
    "    model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.0, return_sequences=True))\n",
    "    \n",
    "    # Dense layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=4, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='SGD',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "avg_acc = 0\n",
    "for train_idx, test_idx in tt_splits:\n",
    "    X_train = X[train_idx]\n",
    "    y_train = y_cat[train_idx]\n",
    "    X_test = X[test_idx]\n",
    "    y_test = y_cat[test_idx]\n",
    "    \n",
    "    model = make_LSTM()\n",
    "    \n",
    "    history = model.fit(X_train, y_train, validation_split=val_split, epochs=num_epochs, batch_size=batch_size)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    metrics = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "    avg_acc += metrics[1]\n",
    "    print(metrics)\n",
    "    break\n",
    "\n",
    "avg_acc /= num_folds\n",
    "print(avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM model\n",
    "\n",
    "# Simple LSTM model with stacked LSTM layers (inspiration from NLP) - many layers, with dropout\n",
    "# LSTM layer accepts data in the form (samples, timesteps, features)\n",
    "\n",
    "def make_LSTM():\n",
    "    # input is of the form: (sample, spatial, temporal)\n",
    "    model = Sequential()\n",
    "    model.add(Permute((2, 1), input_shape=(22, 1000)))\n",
    "    \n",
    "    # LSTM layers\n",
    "    model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.0, return_sequences=True))\n",
    "    model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.0, return_sequences=True))\n",
    "    model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.0, return_sequences=True))\n",
    "    model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.0, return_sequences=True))\n",
    "    model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.0, return_sequences=True))\n",
    "    \n",
    "    # Dense layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=4, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='SGD',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "avg_acc = 0\n",
    "for train_idx, test_idx in tt_splits:\n",
    "    X_train = X[train_idx]\n",
    "    y_train = y_cat[train_idx]\n",
    "    X_test = X[test_idx]\n",
    "    y_test = y_cat[test_idx]\n",
    "    \n",
    "    model = make_LSTM()\n",
    "    \n",
    "    history = model.fit(X_train, y_train, validation_split=val_split, epochs=num_epochs, batch_size=batch_size)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    metrics = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "    avg_acc += metrics[1]\n",
    "    print(metrics)\n",
    "    break\n",
    "\n",
    "avg_acc /= num_folds\n",
    "print(avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GRU model\n",
    "\n",
    "# GRU uses less params than LSTM, for faster training\n",
    "# Simple GRU model with stacked GRU layers (inspiration from NLP) - 3 layers, with dropout\n",
    "# GRU layer accepts data in the form (samples, timesteps, features)\n",
    "\n",
    "def make_GRU():\n",
    "    # input is of the form: (sample, spatial, temporal)\n",
    "    model = Sequential()\n",
    "    model.add(Permute((2, 1), input_shape=(22, 1000)))\n",
    "    \n",
    "    # GRU layers\n",
    "    model.add(GRU(64, dropout=0.2, recurrent_dropout=0.0, return_sequences=True))\n",
    "    model.add(GRU(64, dropout=0.2, recurrent_dropout=0.0, return_sequences=True))\n",
    "    model.add(GRU(64, dropout=0.2, recurrent_dropout=0.0, return_sequences=True))\n",
    "    \n",
    "    # Dense layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=4, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='SGD',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "avg_acc = 0\n",
    "for train_idx, test_idx in tt_splits:\n",
    "    X_train = X[train_idx]\n",
    "    y_train = y_cat[train_idx]\n",
    "    X_test = X[test_idx]\n",
    "    y_test = y_cat[test_idx]\n",
    "    \n",
    "    model = make_LSTM()\n",
    "    \n",
    "    history = model.fit(X_train, y_train, validation_split=val_split, epochs=num_epochs, batch_size=batch_size)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    metrics = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "    avg_acc += metrics[1]\n",
    "    print(metrics)\n",
    "    break\n",
    "\n",
    "avg_acc /= num_folds\n",
    "print(avg_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece239",
   "language": "python",
   "name": "ece239"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
